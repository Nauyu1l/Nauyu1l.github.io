<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  

  
  <title>第四次作业:猫狗大战挑战赛 | Hexo</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="Part1首先下载了老师给的数据集，完成数据下载之后，需要对数据进行一些预处理： 图片将被整理成 224 × 224 × 3 224\times 224 \times 3224×224×3 的大小，同时还将进行归一化处理。其他的一些对数据的复杂的预处理&#x2F;变换 （normalization, cropping, flipping, jittering 等）可以参照 torchvision.tranf">
<meta property="og:type" content="article">
<meta property="og:title" content="第四次作业:猫狗大战挑战赛">
<meta property="og:url" content="http://example.com/2021/10/21/%E7%AC%AC%E5%9B%9B%E6%AC%A1%E4%BD%9C%E4%B8%9A-%E7%8C%AB%E7%8B%97%E5%A4%A7%E6%88%98%E6%8C%91%E6%88%98%E8%B5%9B/index.html">
<meta property="og:site_name" content="Hexo">
<meta property="og:description" content="Part1首先下载了老师给的数据集，完成数据下载之后，需要对数据进行一些预处理： 图片将被整理成 224 × 224 × 3 224\times 224 \times 3224×224×3 的大小，同时还将进行归一化处理。其他的一些对数据的复杂的预处理&#x2F;变换 （normalization, cropping, flipping, jittering 等）可以参照 torchvision.tranf">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="https://raw.githubusercontent.com/Nauyu1l/ImgHosting/master/img/202110211535259.png">
<meta property="og:image" content="https://raw.githubusercontent.com/Nauyu1l/ImgHosting/master/img/202110211535135.png">
<meta property="og:image" content="https://raw.githubusercontent.com/Nauyu1l/ImgHosting/master/img/202110211535330.png">
<meta property="og:image" content="https://raw.githubusercontent.com/Nauyu1l/ImgHosting/master/img/202110211535347.png">
<meta property="og:image" content="https://raw.githubusercontent.com/Nauyu1l/ImgHosting/master/img/202110211535050.png">
<meta property="og:image" content="https://raw.githubusercontent.com/Nauyu1l/ImgHosting/master/img/202110211535838.png">
<meta property="article:published_time" content="2021-10-21T07:13:44.000Z">
<meta property="article:modified_time" content="2021-10-21T07:36:10.754Z">
<meta property="article:author" content="John Doe">
<meta property="article:tag" content="SE">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://raw.githubusercontent.com/Nauyu1l/ImgHosting/master/img/202110211535259.png">
  
    <link rel="alternate" href="/atom.xml" title="Hexo" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.png">
  
  
    <link href="//fonts.googleapis.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  
  
<link rel="stylesheet" href="/css/style.css">

<meta name="generator" content="Hexo 5.4.0"></head>

<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">Hexo</a>
      </h1>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
          <a id="nav-rss-link" class="nav-icon" href="/atom.xml" title="RSS Feed"></a>
        
        <a id="nav-search-btn" class="nav-icon" title="Search"></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="http://example.com"></form>
      </div>
    </div>
  </div>
</header>
      <div class="outer">
        <section id="main"><article id="post-第四次作业-猫狗大战挑战赛" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2021/10/21/%E7%AC%AC%E5%9B%9B%E6%AC%A1%E4%BD%9C%E4%B8%9A-%E7%8C%AB%E7%8B%97%E5%A4%A7%E6%88%98%E6%8C%91%E6%88%98%E8%B5%9B/" class="article-date">
  <time datetime="2021-10-21T07:13:44.000Z" itemprop="datePublished">2021-10-21</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 class="article-title" itemprop="name">
      第四次作业:猫狗大战挑战赛
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h1 id="Part1"><a href="#Part1" class="headerlink" title="Part1"></a>Part1</h1><p>首先下载了老师给的数据集，完成数据下载之后，需要对数据进行一些预处理：</p>
<p>图片将被整理成 224 × 224 × 3 224\times 224 \times 3224×224×3 的大小，同时还将进行归一化处理。<br>其他的一些对数据的复杂的预处理/变换 （normalization, cropping, flipping, jittering 等）可以参照 torchvision.tranforms 的官方文档说明。同时将数据拆分为训练集和测试集，将部分图片打印出来可视化以方便测试。</p>
<p>VGG模型提出了迁移学习，所以我们只需要更改最后两层即可，设置梯度下降为FALSE，我们只需要训练测试全连接层即可。</p>
<p><img src="https://raw.githubusercontent.com/Nauyu1l/ImgHosting/master/img/202110211535259.png" alt="屏幕截图 2021-10-20 190935"></p>
<p><img src="https://raw.githubusercontent.com/Nauyu1l/ImgHosting/master/img/202110211535135.png" alt="屏幕截图 2021-10-20 190954"></p>
<p>之后测试为如上图所示的结果。</p>
<h1 id="part2"><a href="#part2" class="headerlink" title="part2"></a>part2</h1><p>猫狗大战比赛：</p>
<p>有了老师提供的代码，在其基础上做了一些更改。</p>
<p>首先下载数据集，unrar解压文件。注意到解压后的文件中，val和train中都没有分类出前缀为cat和dog的图片，于是我们要运行脚本将其分离。</p>
<p>运行完以后，如图</p>
<p><img src="https://raw.githubusercontent.com/Nauyu1l/ImgHosting/master/img/202110211535330.png" alt="QQ图片20211021131113"></p>
<p>接下来是我对于代码的改动部分：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torchvision</span><br><span class="line"><span class="keyword">from</span> torchvision <span class="keyword">import</span> models,transforms,datasets</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">import</span> json</span><br><span class="line"><span class="comment"># 判断是否存在GPU设备</span></span><br><span class="line">device = torch.device(<span class="string">&quot;cuda:0&quot;</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">&quot;cpu&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;Using gpu: %s &#x27;</span> % torch.cuda.is_available())</span><br><span class="line"><span class="comment">#处理数据</span></span><br><span class="line">normalize = transforms.Normalize(mean=[<span class="number">0.485</span>, <span class="number">0.456</span>, <span class="number">0.406</span>], std=[<span class="number">0.229</span>, <span class="number">0.224</span>, <span class="number">0.225</span>])</span><br><span class="line">vgg_format = transforms.Compose([</span><br><span class="line">                 transforms.CenterCrop(<span class="number">224</span>),</span><br><span class="line">                 transforms.ToTensor(),</span><br><span class="line">                 normalize,</span><br><span class="line">               ])</span><br><span class="line"> </span><br><span class="line">data_dir = <span class="string">&quot;/content/cat_dog&quot;</span></span><br><span class="line"> </span><br><span class="line">dsets = &#123;x: datasets.ImageFolder(os.path.join(data_dir, x), vgg_format)</span><br><span class="line">           <span class="keyword">for</span> x <span class="keyword">in</span> [<span class="string">&#x27;train&#x27;</span>, <span class="string">&#x27;val&#x27;</span>]&#125;</span><br><span class="line">   </span><br><span class="line">dset_sizes = &#123;x: <span class="built_in">len</span>(dsets[x]) <span class="keyword">for</span> x <span class="keyword">in</span> [<span class="string">&#x27;train&#x27;</span>, <span class="string">&#x27;val&#x27;</span>]&#125;</span><br><span class="line">dset_classes = dsets[<span class="string">&#x27;train&#x27;</span>].classes</span><br><span class="line"></span><br><span class="line"><span class="comment">#修改batch_size</span></span><br><span class="line">loader_train = torch.utils.data.DataLoader(dsets[<span class="string">&#x27;train&#x27;</span>], batch_size=<span class="number">128</span>, shuffle=<span class="literal">True</span>, num_workers=<span class="number">6</span>)</span><br><span class="line">loader_valid = torch.utils.data.DataLoader(dsets[<span class="string">&#x27;val&#x27;</span>], batch_size=<span class="number">5</span>, shuffle=<span class="literal">False</span>, num_workers=<span class="number">6</span>)</span><br><span class="line"><span class="comment">#加载vgg16模型</span></span><br><span class="line">!wget https://s3.amazonaws.com/deep-learning-models/image-models/imagenet_class_index.json</span><br><span class="line"><span class="comment">#使用vgg16需要</span></span><br><span class="line">model_vgg = models.vgg16(pretrained=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(model_vgg)</span><br><span class="line"> </span><br><span class="line">model_vgg_new = model_vgg;</span><br><span class="line"> </span><br><span class="line"><span class="comment">#冻结VGG16中的参数，不进行梯度下降</span></span><br><span class="line"><span class="keyword">for</span> param <span class="keyword">in</span> model_vgg_new.parameters():</span><br><span class="line">    param.requires_grad = <span class="literal">False</span></span><br><span class="line"><span class="comment">#修改模型后两层</span></span><br><span class="line">model_vgg_new.classifier._modules[<span class="string">&#x27;6&#x27;</span>] = nn.Linear(<span class="number">4096</span>, <span class="number">2</span>)</span><br><span class="line">model_vgg_new.classifier._modules[<span class="string">&#x27;7&#x27;</span>] = torch.nn.LogSoftmax(dim = <span class="number">1</span>)</span><br><span class="line">model_vgg_new = model_vgg_new.to(device)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(model_vgg_new.classifier)</span><br><span class="line"></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">第一步：创建损失函数和优化器</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">损失函数 NLLLoss() 的 输入 是一个对数概率向量和一个目标标签.</span></span><br><span class="line"><span class="string">它不会为我们计算对数概率，适合最后一层是log_softmax()的网络.</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">criterion = nn.NLLLoss()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 学习率</span></span><br><span class="line">lr = <span class="number">0.001</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#修改为Adam优化器</span></span><br><span class="line">optimizer_vgg = torch.optim.Adam(model_vgg_new.classifier[<span class="number">6</span>].parameters(), lr=lr)</span><br><span class="line"></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">第二步：训练模型</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">train_model</span>(<span class="params">model,dataloader,size,epochs=<span class="number">1</span>,optimizer=<span class="literal">None</span></span>):</span></span><br><span class="line">    model.train()</span><br><span class="line">    max_acc = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(epochs):</span><br><span class="line">        running_loss = <span class="number">0.0</span></span><br><span class="line">        running_corrects = <span class="number">0</span></span><br><span class="line">        count = <span class="number">0</span></span><br><span class="line">        <span class="keyword">for</span> inputs,classes <span class="keyword">in</span> dataloader:</span><br><span class="line">            inputs = inputs.to(device)</span><br><span class="line">            classes = classes.to(device)</span><br><span class="line">            outputs = model(inputs)</span><br><span class="line">            loss = criterion(outputs,classes)           </span><br><span class="line">            optimizer = optimizer</span><br><span class="line">            optimizer.zero_grad()</span><br><span class="line">            loss.backward()</span><br><span class="line">            optimizer.step()</span><br><span class="line">            _,preds = torch.<span class="built_in">max</span>(outputs.data,<span class="number">1</span>)</span><br><span class="line">            <span class="comment"># statistics</span></span><br><span class="line">            running_loss += loss.data.item()</span><br><span class="line">            running_corrects += torch.<span class="built_in">sum</span>(preds == classes.data)</span><br><span class="line">            count += <span class="built_in">len</span>(inputs)</span><br><span class="line">            <span class="comment">#print(&#x27;Training: No. &#x27;, count, &#x27; process ... total: &#x27;, size)</span></span><br><span class="line">        epoch_loss = running_loss / size</span><br><span class="line">        epoch_acc = running_corrects.data.item() / size</span><br><span class="line"></span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;epoch: &#123;:&#125; Loss: &#123;:.4f&#125; Acc: &#123;:.4f&#125;\n&#x27;</span>.<span class="built_in">format</span>(epoch,epoch_loss, epoch_acc))</span><br><span class="line">        <span class="keyword">if</span> epoch_acc &gt; max_acc:</span><br><span class="line">          max_acc = epoch_acc</span><br><span class="line">          path = <span class="string">&#x27;./sample_data&#x27;</span> + <span class="built_in">str</span>(epoch+<span class="number">1</span>) + <span class="string">&#x27;&#x27;</span> + <span class="built_in">str</span>(epoch_acc) + <span class="string">&#x27;&#x27;</span> + <span class="string">&#x27;.pth&#x27;</span></span><br><span class="line">          torch.save(model, path)</span><br><span class="line">          <span class="built_in">print</span>(<span class="string">&quot;save: &quot;</span>, path,<span class="string">&quot;\n&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 模型训练,修改训练次数10次</span></span><br><span class="line">train_model(model_vgg_new, loader_train, size=dset_sizes[<span class="string">&#x27;train&#x27;</span>], epochs=<span class="number">10</span>,</span><br><span class="line">            optimizer=optimizer_vgg)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 第三步：测试模型</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">test_model</span>(<span class="params">model,dataloader,size</span>):</span></span><br><span class="line">    model.<span class="built_in">eval</span>()</span><br><span class="line">    predictions = np.zeros(size)</span><br><span class="line">    all_classes = np.zeros(size)</span><br><span class="line">    all_proba = np.zeros((size,<span class="number">2</span>))</span><br><span class="line">    i = <span class="number">0</span></span><br><span class="line">    running_loss = <span class="number">0.0</span></span><br><span class="line">    running_corrects = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> inputs,classes <span class="keyword">in</span> dataloader:</span><br><span class="line">        inputs = inputs.to(device)</span><br><span class="line">        classes = classes.to(device)</span><br><span class="line">        outputs = model(inputs)</span><br><span class="line">        loss = criterion(outputs,classes)           </span><br><span class="line">        _,preds = torch.<span class="built_in">max</span>(outputs.data,<span class="number">1</span>)</span><br><span class="line">        <span class="comment"># statistics</span></span><br><span class="line">        running_loss += loss.data.item()</span><br><span class="line">        running_corrects += torch.<span class="built_in">sum</span>(preds == classes.data)</span><br><span class="line">        predictions[i:i+<span class="built_in">len</span>(classes)] = preds.to(<span class="string">&#x27;cpu&#x27;</span>).numpy()</span><br><span class="line">        all_classes[i:i+<span class="built_in">len</span>(classes)] = classes.to(<span class="string">&#x27;cpu&#x27;</span>).numpy()</span><br><span class="line">        all_proba[i:i+<span class="built_in">len</span>(classes),:] = outputs.data.to(<span class="string">&#x27;cpu&#x27;</span>).numpy()</span><br><span class="line">        i += <span class="built_in">len</span>(classes)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;Testing: No. &#x27;</span>, i, <span class="string">&#x27; process ... total: &#x27;</span>, size)        </span><br><span class="line">    epoch_loss = running_loss / size</span><br><span class="line">    epoch_acc = running_corrects.data.item() / size</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;Loss: &#123;:.4f&#125; Acc: &#123;:.4f&#125;&#x27;</span>.<span class="built_in">format</span>(</span><br><span class="line">                     epoch_loss, epoch_acc))</span><br><span class="line">    <span class="keyword">return</span> predictions, all_proba, all_classes</span><br><span class="line"></span><br><span class="line"><span class="comment"># 模型测试</span></span><br><span class="line">predictions, all_proba, all_classes = test_model(model_vgg_new,loader_valid,size=dset_sizes[<span class="string">&#x27;val&#x27;</span>])</span><br></pre></td></tr></table></figure>

<p>总结起来有以下几点：</p>
<p>1.修改batch_size为128</p>
<p>2.使用Adam优化</p>
<p>3.增加训练次数，保存训练模型以选择最优模型。</p>
<p><img src="https://raw.githubusercontent.com/Nauyu1l/ImgHosting/master/img/202110211535347.png" alt="QQ图片20211021135318"></p>
<p><img src="https://raw.githubusercontent.com/Nauyu1l/ImgHosting/master/img/202110211535050.png" alt="QQ图片20211021135246"></p>
<p>然后选取最佳的模型10号（盲猜训练次数越多正确率越高，且随次数呈正相关）</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> torchvision <span class="keyword">import</span> transforms,datasets</span><br><span class="line"><span class="keyword">from</span> tqdm <span class="keyword">import</span> tqdm</span><br><span class="line">device = torch.device(<span class="string">&quot;cuda:0&quot;</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">&quot;cpu&quot;</span>) </span><br><span class="line">normalize = transforms.Normalize(mean=[<span class="number">0.485</span>, <span class="number">0.456</span>, <span class="number">0.406</span>], std=[<span class="number">0.229</span>, <span class="number">0.224</span>, <span class="number">0.225</span>])</span><br><span class="line">vgg_format = transforms.Compose([</span><br><span class="line">                transforms.CenterCrop(<span class="number">224</span>),</span><br><span class="line">                transforms.ToTensor(),</span><br><span class="line">                normalize,</span><br><span class="line">            ])</span><br><span class="line"></span><br><span class="line">dsets_mine = datasets.ImageFolder(<span class="string">r&quot;/content/cat_dog&quot;</span>, vgg_format)</span><br><span class="line">loader_test = torch.utils.data.DataLoader(dsets_mine, batch_size=<span class="number">1</span>, shuffle=<span class="literal">False</span>, num_workers=<span class="number">0</span>)</span><br><span class="line">model_vgg_new = torch.load(<span class="string">r&#x27;/content/sample_data100.98115.pth&#x27;</span>)</span><br><span class="line">model_vgg_new = model_vgg_new.to(device)</span><br><span class="line">dic = &#123;&#125;</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">test</span>(<span class="params">model,dataloader,size</span>):</span></span><br><span class="line">    model.<span class="built_in">eval</span>()</span><br><span class="line">    predictions = np.zeros(size)</span><br><span class="line">    cnt = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> inputs,_ <span class="keyword">in</span> tqdm(dataloader):</span><br><span class="line">        inputs = inputs.to(device)</span><br><span class="line">        outputs = model(inputs)</span><br><span class="line">        _,preds = torch.<span class="built_in">max</span>(outputs.data,<span class="number">1</span>)    </span><br><span class="line">        <span class="comment">#这里是切割路径，因为dset中的数据不是按1-2000顺序排列的</span></span><br><span class="line">        key = dsets_mine.imgs[cnt][<span class="number">0</span>].split(<span class="string">&quot;\\&quot;</span>)[-<span class="number">1</span>].split(<span class="string">&#x27;.&#x27;</span>)[<span class="number">0</span>]</span><br><span class="line">        dic[key] = preds[<span class="number">0</span>]</span><br><span class="line">        cnt = cnt +<span class="number">1</span></span><br><span class="line">test(model_vgg_new,loader_test,size=<span class="number">2000</span>)</span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&quot;result.csv&quot;</span>,<span class="string">&#x27;a+&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">    <span class="keyword">for</span> key <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">2000</span>):</span><br><span class="line">        f.write(<span class="string">&quot;&#123;&#125;,&#123;&#125;\n&quot;</span>.<span class="built_in">format</span>(key,dic[<span class="string">&quot;/content/cat_dog/test/&quot;</span>+<span class="built_in">str</span>(key)]))</span><br></pre></td></tr></table></figure>

<p>这里一开始遇到了一些问题：</p>
<p>1.colab排序是按首位最优先排序，不按位数，所以容易错位 造成1  10 100 1000 2这种错误。</p>
<p>2.关于如何输出csv查阅了相关资料。</p>
<p>得到csv文件后，提交<img src="https://raw.githubusercontent.com/Nauyu1l/ImgHosting/master/img/202110211535838.png" alt="QQ图片20211021153118"></p>
<p>98，挺整齐的还可以，跟10号的98.11差不多，可以接受。</p>
<p>小结：1.适当扩充训练集。</p>
<p>​            2.更换更合适的优化器</p>
<p>​            3.更改batch_size</p>
<p>​            4.迁移学习富有魅力</p>
<p>​                </p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://example.com/2021/10/21/%E7%AC%AC%E5%9B%9B%E6%AC%A1%E4%BD%9C%E4%B8%9A-%E7%8C%AB%E7%8B%97%E5%A4%A7%E6%88%98%E6%8C%91%E6%88%98%E8%B5%9B/" data-id="ckv0mrx3b00007sveguoqhk5c" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/SE/" rel="tag">SE</a></li></ul>

    </footer>
  </div>
  
    
<nav id="article-nav">
  
  
    <a href="/2021/10/13/%E7%AC%AC3%E6%AC%A1%E4%BD%9C%E4%B8%9A%EF%BC%9A%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/" id="article-nav-older" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Older</strong>
      <div class="article-nav-title">第3次作业：卷积神经网络</div>
    </a>
  
</nav>

  
</article>

</section>
        
          <aside id="sidebar">
  
    

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tags</h3>
    <div class="widget">
      <ul class="tag-list" itemprop="keywords"><li class="tag-list-item"><a class="tag-list-link" href="/tags/SE/" rel="tag">SE</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/life/" rel="tag">life</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E6%95%B4%E6%B4%BB/" rel="tag">整活</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%F0%9F%91%B4/" rel="tag">👴</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tag Cloud</h3>
    <div class="widget tagcloud">
      <a href="/tags/SE/" style="font-size: 20px;">SE</a> <a href="/tags/life/" style="font-size: 10px;">life</a> <a href="/tags/%E6%95%B4%E6%B4%BB/" style="font-size: 10px;">整活</a> <a href="/tags/%F0%9F%91%B4/" style="font-size: 10px;">👴</a>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2021/10/">October 2021</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2021/08/">August 2021</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Recent Posts</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2021/10/21/%E7%AC%AC%E5%9B%9B%E6%AC%A1%E4%BD%9C%E4%B8%9A-%E7%8C%AB%E7%8B%97%E5%A4%A7%E6%88%98%E6%8C%91%E6%88%98%E8%B5%9B/">第四次作业:猫狗大战挑战赛</a>
          </li>
        
          <li>
            <a href="/2021/10/13/%E7%AC%AC3%E6%AC%A1%E4%BD%9C%E4%B8%9A%EF%BC%9A%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/">第3次作业：卷积神经网络</a>
          </li>
        
          <li>
            <a href="/2021/10/01/%E7%AC%AC%E4%B8%80%E6%AC%A1%E4%BD%9C%E4%B8%9A%EF%BC%9A%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/">第一次作业：深度学习基础</a>
          </li>
        
          <li>
            <a href="/2021/08/16/ya%E7%9A%84%E5%89%8D%E5%8D%8A%E7%94%9F/">ya的前半生</a>
          </li>
        
          <li>
            <a href="/2021/08/09/%E9%9F%A6%E8%BE%BE%E8%B7%B3%E8%B7%83/">韦达跳跃</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2021 John Doe<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>
    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>
    

<script src="//ajax.googleapis.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>


  
<link rel="stylesheet" href="/fancybox/jquery.fancybox.css">

  
<script src="/fancybox/jquery.fancybox.pack.js"></script>




<script src="/js/script.js"></script>




  </div>
</body>
</html>